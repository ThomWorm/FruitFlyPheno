{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydap.client import open_url\n",
    "import os\n",
    "from pydap.client import open_url\n",
    "import xarray as xr\n",
    "import datetime\n",
    "from datetime import timedelta, date\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "from net_cdf_functions import *\n",
    "from degree_day_equations import single_sine_horizontal_cutoff\n",
    "import numpy as np\n",
    "from processing_functions import *\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.array as da\n",
    "\n",
    "# %matplotlib inline\n",
    "# import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "# check if port is already in use\n",
    "\n",
    "# client = Client(n_workers=3, threads_per_worker=1, memory_limit=\"2GB\")\n",
    "# client\n",
    "\n",
    "data_path = \"/media/thom/Q/data/\"\n",
    "# data_path = 'data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 44941 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-a771d1ed-59bc-11ef-adc8-c87f547c6d0f</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:44941/status\" target=\"_blank\">http://127.0.0.1:44941/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">43c2f3e7</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:44941/status\" target=\"_blank\">http://127.0.0.1:44941/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 3\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 6\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 5.59 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-4388968e-81e4-4629-8f76-e481c71afe25</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:39515\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 3\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:44941/status\" target=\"_blank\">http://127.0.0.1:44941/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 6\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 5.59 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:35341\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:43029/status\" target=\"_blank\">http://127.0.0.1:43029/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 1.86 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:33709\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-_geqkpbj\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:45935\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:39503/status\" target=\"_blank\">http://127.0.0.1:39503/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 1.86 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:44775\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-lj3h4d1p\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:40403\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:38581/status\" target=\"_blank\">http://127.0.0.1:38581/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 1.86 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:38741\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-z37v7_pt\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:39515' processes=3 threads=6, memory=5.59 GiB>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(n_workers=3, threads_per_worker=2, memory_limit=\"2GB\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor year in range(2020, 2021):\\n    for day in range(1, 2):\\n        fetch_and_save_data(year, 2, 10, data_path)\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# download data for eyars 2000 for january first\n",
    "\"\"\"\n",
    "for year in range(2020, 2021):\n",
    "    for day in range(1, 2):\n",
    "        fetch_and_save_data(year, 2, 10, data_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for 20190101 to /media/thom/Q/data/PRISM/2019/PRISM_combo_20190101.nc\n",
      "Saved data for 20190102 to /media/thom/Q/data/PRISM/2019/PRISM_combo_20190102.nc\n",
      "Saved data for 20190103 to /media/thom/Q/data/PRISM/2019/PRISM_combo_20190103.nc\n",
      "Saved data for 20190104 to /media/thom/Q/data/PRISM/2019/PRISM_combo_20190104.nc\n",
      "Saved data for 20190105 to /media/thom/Q/data/PRISM/2019/PRISM_combo_20190105.nc\n",
      "Saved data for 20190106 to /media/thom/Q/data/PRISM/2019/PRISM_combo_20190106.nc\n",
      "Saved data for 20190107 to /media/thom/Q/data/PRISM/2019/PRISM_combo_20190107.nc\n",
      "Saved data for 20190108 to /media/thom/Q/data/PRISM/2019/PRISM_combo_20190108.nc\n",
      "Saved data for 20190109 to /media/thom/Q/data/PRISM/2019/PRISM_combo_20190109.nc\n",
      "Saved data for 20190110 to /media/thom/Q/data/PRISM/2019/PRISM_combo_20190110.nc\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# fetch and save data 2000-2020\n",
    "for year in range(2019, 2020):\n",
    "    fetch_and_save_data(year, 1, 10, data_path)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating degree days for 1D data array\n",
      "calculating degree days for 3D data array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: invalid value encountered in func (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    }
   ],
   "source": [
    "prism_year_stack = xr.open_mfdataset(\n",
    "    data_path + \"PRISM/*/PRISM_combo_*.nc\",\n",
    "    # combine=\"by_coords\",\n",
    "    drop_variables=[\"ppt\", \"tmean\"],\n",
    ")\n",
    "# prism_year_stack = prism_year_stack.chunk({\"latitude\": 100, \"longitude\": 100})\n",
    "\n",
    "la_single = subset_dataset_by_coords(prism_year_stack, 34.05, -118.25, window_size=None)\n",
    "la_window = subset_dataset_by_coords(prism_year_stack, 33.896252, -118.408213, 0.25)\n",
    "la_single_dd = da_calculate_degree_days(12, 36, la_single)\n",
    "la_window_dd = da_calculate_degree_days(12, 36, la_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold reach dates for each cell:\n",
      "[['2024-01-07' '2024-01-08' '2024-01-07' '2024-01-08' '2024-01-10'\n",
      "  '2024-01-11' '2024-01-09' '2024-01-11' '2024-01-07' '2024-01-06']\n",
      " ['2024-01-04' '2024-01-04' '2024-01-06' '2024-01-05' '2024-01-04'\n",
      "  '2024-01-07' '2024-01-03' '2024-01-05' '2024-01-08' '2024-01-06']\n",
      " ['2024-01-09' '2024-01-07' '2024-01-05' '2024-01-07' '2024-01-06'\n",
      "  '2024-01-05' '2024-01-07' '2024-01-05' '2024-01-05' '2024-01-07']\n",
      " ['2024-01-05' '2024-01-04' '2024-01-05' '2024-01-07' '2024-01-04'\n",
      "  '2024-01-08' '2024-01-09' '2024-01-08' '2024-01-04' '2024-01-08']\n",
      " ['2024-01-10' '2024-01-08' '2024-01-06' '2024-01-05' '2024-01-09'\n",
      "  '2024-01-07' '2024-01-06' '2024-01-07' '2024-01-03' '2024-01-06']\n",
      " ['2024-01-04' '2024-01-07' '2024-01-10' '2024-01-03' '2024-01-06'\n",
      "  '2024-01-05' '2024-01-07' '2024-01-09' '2024-01-06' '2024-01-07']\n",
      " ['2024-01-07' '2024-01-04' '2024-01-04' '2024-01-05' '2024-01-05'\n",
      "  '2024-01-09' '2024-01-05' '2024-01-10' '2024-01-06' '2024-01-09']\n",
      " ['2024-01-06' '2024-01-08' '2024-01-05' '2024-01-09' '2024-01-06'\n",
      "  '2024-01-06' '2024-01-08' '2024-01-14' '2024-01-06' '2024-01-09']\n",
      " ['2024-01-04' '2024-01-05' '2024-01-03' '2024-01-04' '2024-01-06'\n",
      "  '2024-01-07' '2024-01-06' '2024-01-04' '2024-01-05' '2024-01-10']\n",
      " ['2024-01-07' '2024-01-09' '2024-01-06' '2024-01-07' '2024-01-05'\n",
      "  '2024-01-08' '2024-01-06' '2024-01-06' '2024-01-04' '2024-01-08']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "def day_cumsum_reaches_threshold(degree_days, start_day, threshold):\n",
    "    cumsum = degree_days.sel(t=slice(start_day, None)).cumsum()\n",
    "    # date = cumsum.where(cumsum >= threshold, drop=True)[0]['t']\n",
    "    date = (\n",
    "        cumsum.where(cumsum >= threshold, drop=True)\n",
    "        .isel(t=0)[\"t\"]\n",
    "        .values.astype(\"datetime64[D]\")\n",
    "    )\n",
    "\n",
    "    return date\n",
    "\n",
    "\n",
    "def apply_cumsum_threshold(dataset, start_day, threshold):\n",
    "    result = xr.apply_ufunc(\n",
    "        day_cumsum_reaches_threshold,\n",
    "        dataset,\n",
    "        input_core_dims=[[\"t\"]],\n",
    "        output_core_dims=[[]],\n",
    "        # vectorize=True,\n",
    "        dask=\"parallelized\",\n",
    "        kwargs={\"start_day\": start_day, \"threshold\": threshold},\n",
    "        output_dtypes=[np.datetime64],\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def day_cumsum_reaches_threshold_linear(degree_days, start_dates, threshold):\n",
    "    # Convert start_dates to indices based on the time dimension\n",
    "    # print(degree_days.time.values)\n",
    "    start_indices = np.array(\n",
    "        [\n",
    "            np.where(degree_days.time.values == pd.Timestamp(d))[0][0]\n",
    "            for d in start_dates.flatten()\n",
    "        ]\n",
    "    ).reshape(start_dates.shape)\n",
    "\n",
    "    # Initialize an array to store results\n",
    "    results = np.full(start_dates.shape, np.datetime64(\"NaT\"), dtype=\"datetime64[D]\")\n",
    "    for i in range(degree_days.sizes[\"lat\"]):\n",
    "        for j in range(degree_days.sizes[\"lon\"]):\n",
    "            start_date = start_dates[i, j]\n",
    "            start_index = start_indices[i, j]\n",
    "\n",
    "            if pd.Timestamp(start_date) not in degree_days.time.values:\n",
    "                # If start_date is not in the time dimension, skip\n",
    "                print(f\"Start date {start_date} not found in time dimension\")\n",
    "                continue\n",
    "\n",
    "            # Compute cumulative sum\n",
    "            cumsum = np.cumsum(degree_days[i, j, start_index:])\n",
    "            # print(start_index)\n",
    "            # print(cumsum)\n",
    "            # Find where the threshold is reached\n",
    "            threshold_reached = np.where(cumsum >= threshold)[0]\n",
    "\n",
    "            if len(threshold_reached) > 0:\n",
    "                # Convert index to date\n",
    "                result_date = degree_days.time.values[\n",
    "                    start_index + threshold_reached[0]\n",
    "                ]\n",
    "                results[i, j] = np.datetime64(result_date, \"D\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Sample Data Creation\n",
    "time_length = 50\n",
    "dates = pd.date_range(start=\"2024-01-01\", periods=time_length, freq=\"D\")\n",
    "\n",
    "# Create a sample DataArray for degree_days\n",
    "lat = 10\n",
    "lon = 10\n",
    "degree_days = np.random.rand(lat, lon, time_length) * 10  # Random degree_days values\n",
    "da_degree_days = xr.DataArray(\n",
    "    degree_days, dims=[\"lat\", \"lon\", \"time\"], coords={\"time\": dates}\n",
    ")\n",
    "\n",
    "# Define start days as actual dates within the first 5 days\n",
    "start_dates = pd.date_range(start=\"2024-01-01\", periods=5, freq=\"D\")\n",
    "start_days = np.random.choice(start_dates, size=(lat, lon))\n",
    "\n",
    "# Apply the function\n",
    "threshold = 20\n",
    "result_dates = day_cumsum_reaches_threshold_linear(\n",
    "    da_degree_days, start_days, threshold\n",
    ")\n",
    "print(\"Threshold reach dates for each cell:\")\n",
    "print(result_dates)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;random_sample-280a407ce309bd2357d25d8acf7e02e7&#x27; (lat: 10,\n",
       "                                                                    lon: 10)&gt; Size: 800B\n",
       "array([[9.491904e+17, 9.494496e+17, 9.492768e+17, 9.493632e+17,\n",
       "        9.492768e+17, 9.496224e+17, 9.497088e+17, 9.488448e+17,\n",
       "        9.496224e+17, 9.491040e+17],\n",
       "       [9.494496e+17, 9.491904e+17, 9.501408e+17, 9.494496e+17,\n",
       "        9.496224e+17, 9.494496e+17, 9.497088e+17, 9.491040e+17,\n",
       "        9.491040e+17, 9.493632e+17],\n",
       "       [9.496224e+17, 9.492768e+17, 9.491040e+17, 9.490176e+17,\n",
       "        9.491904e+17, 9.495360e+17, 9.491904e+17, 9.497088e+17,\n",
       "        9.489312e+17, 9.494496e+17],\n",
       "       [9.491904e+17, 9.488448e+17, 9.495360e+17, 9.493632e+17,\n",
       "        9.492768e+17, 9.497088e+17, 9.494496e+17, 9.494496e+17,\n",
       "        9.496224e+17, 9.490176e+17],\n",
       "       [9.494496e+17, 9.498816e+17, 9.493632e+17, 9.489312e+17,\n",
       "        9.494496e+17, 9.490176e+17, 9.494496e+17, 9.495360e+17,\n",
       "        9.496224e+17, 9.491040e+17],\n",
       "       [9.497088e+17, 9.492768e+17, 9.494496e+17, 9.497088e+17,\n",
       "        9.499680e+17, 9.496224e+17, 9.493632e+17, 9.490176e+17,\n",
       "        9.492768e+17, 9.493632e+17],\n",
       "       [9.493632e+17, 9.496224e+17, 9.491040e+17, 9.490176e+17,\n",
       "        9.491040e+17, 9.497088e+17, 9.491904e+17, 9.497952e+17,\n",
       "        9.497088e+17, 9.491040e+17],\n",
       "       [9.490176e+17, 9.496224e+17, 9.495360e+17, 9.490176e+17,\n",
       "        9.493632e+17, 9.491904e+17, 9.496224e+17, 9.489312e+17,\n",
       "        9.504000e+17, 9.491904e+17],\n",
       "       [9.492768e+17, 9.493632e+17, 9.489312e+17, 9.497952e+17,\n",
       "        9.497952e+17, 9.495360e+17, 9.495360e+17, 9.486720e+17,\n",
       "        9.494496e+17, 9.493632e+17],\n",
       "       [9.494496e+17, 9.494496e+17, 9.497952e+17, 9.493632e+17,\n",
       "        9.490176e+17, 9.491040e+17, 9.491040e+17, 9.493632e+17,\n",
       "        9.494496e+17, 9.491040e+17]])\n",
       "Coordinates:\n",
       "  * lat      (lat) float64 80B -90.0 -70.0 -50.0 -30.0 ... 30.0 50.0 70.0 90.0\n",
       "  * lon      (lon) float64 80B -180.0 -140.0 -100.0 -60.0 ... 100.0 140.0 180.0</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'random_sample-280a407ce309bd2357d25d8acf7e02e7'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>lat</span>: 10</li><li><span class='xr-has-index'>lon</span>: 10</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-41cdd468-8902-44b1-b975-62e58e04b92a' class='xr-array-in' type='checkbox' checked><label for='section-41cdd468-8902-44b1-b975-62e58e04b92a' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>9.492e+17 9.494e+17 9.493e+17 ... 9.494e+17 9.494e+17 9.491e+17</span></div><div class='xr-array-data'><pre>array([[9.491904e+17, 9.494496e+17, 9.492768e+17, 9.493632e+17,\n",
       "        9.492768e+17, 9.496224e+17, 9.497088e+17, 9.488448e+17,\n",
       "        9.496224e+17, 9.491040e+17],\n",
       "       [9.494496e+17, 9.491904e+17, 9.501408e+17, 9.494496e+17,\n",
       "        9.496224e+17, 9.494496e+17, 9.497088e+17, 9.491040e+17,\n",
       "        9.491040e+17, 9.493632e+17],\n",
       "       [9.496224e+17, 9.492768e+17, 9.491040e+17, 9.490176e+17,\n",
       "        9.491904e+17, 9.495360e+17, 9.491904e+17, 9.497088e+17,\n",
       "        9.489312e+17, 9.494496e+17],\n",
       "       [9.491904e+17, 9.488448e+17, 9.495360e+17, 9.493632e+17,\n",
       "        9.492768e+17, 9.497088e+17, 9.494496e+17, 9.494496e+17,\n",
       "        9.496224e+17, 9.490176e+17],\n",
       "       [9.494496e+17, 9.498816e+17, 9.493632e+17, 9.489312e+17,\n",
       "        9.494496e+17, 9.490176e+17, 9.494496e+17, 9.495360e+17,\n",
       "        9.496224e+17, 9.491040e+17],\n",
       "       [9.497088e+17, 9.492768e+17, 9.494496e+17, 9.497088e+17,\n",
       "        9.499680e+17, 9.496224e+17, 9.493632e+17, 9.490176e+17,\n",
       "        9.492768e+17, 9.493632e+17],\n",
       "       [9.493632e+17, 9.496224e+17, 9.491040e+17, 9.490176e+17,\n",
       "        9.491040e+17, 9.497088e+17, 9.491904e+17, 9.497952e+17,\n",
       "        9.497088e+17, 9.491040e+17],\n",
       "       [9.490176e+17, 9.496224e+17, 9.495360e+17, 9.490176e+17,\n",
       "        9.493632e+17, 9.491904e+17, 9.496224e+17, 9.489312e+17,\n",
       "        9.504000e+17, 9.491904e+17],\n",
       "       [9.492768e+17, 9.493632e+17, 9.489312e+17, 9.497952e+17,\n",
       "        9.497952e+17, 9.495360e+17, 9.495360e+17, 9.486720e+17,\n",
       "        9.494496e+17, 9.493632e+17],\n",
       "       [9.494496e+17, 9.494496e+17, 9.497952e+17, 9.493632e+17,\n",
       "        9.490176e+17, 9.491040e+17, 9.491040e+17, 9.493632e+17,\n",
       "        9.494496e+17, 9.491040e+17]])</pre></div></div></li><li class='xr-section-item'><input id='section-e9037862-ecc2-46f4-9fdf-18f404d2d76d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-e9037862-ecc2-46f4-9fdf-18f404d2d76d' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-90.0 -70.0 -50.0 ... 70.0 90.0</div><input id='attrs-39983d71-9a42-4d94-9a35-5c990de80fa8' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-39983d71-9a42-4d94-9a35-5c990de80fa8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6d35f0e0-2d1c-477d-ab40-72d5e4f48151' class='xr-var-data-in' type='checkbox'><label for='data-6d35f0e0-2d1c-477d-ab40-72d5e4f48151' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-90., -70., -50., -30., -10.,  10.,  30.,  50.,  70.,  90.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-180.0 -140.0 ... 140.0 180.0</div><input id='attrs-38b5281a-4ddf-4093-a0c1-d36e59c83154' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-38b5281a-4ddf-4093-a0c1-d36e59c83154' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-654ab07d-be99-41bd-a8da-9ecc837e476c' class='xr-var-data-in' type='checkbox'><label for='data-654ab07d-be99-41bd-a8da-9ecc837e476c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,  180.])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-dcfa5325-8f62-49cb-92d1-d68c0de1bc32' class='xr-section-summary-in' type='checkbox'  ><label for='section-dcfa5325-8f62-49cb-92d1-d68c0de1bc32' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-d9835710-7d61-4072-82a2-c42f3cd3e796' class='xr-index-data-in' type='checkbox'/><label for='index-d9835710-7d61-4072-82a2-c42f3cd3e796' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-90.0, -70.0, -50.0, -30.0, -10.0, 10.0, 30.0, 50.0, 70.0, 90.0], dtype=&#x27;float64&#x27;, name=&#x27;lat&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-80f82f27-819e-4069-85d3-909c7a1f5919' class='xr-index-data-in' type='checkbox'/><label for='index-80f82f27-819e-4069-85d3-909c7a1f5919' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-180.0, -140.0, -100.0, -60.0, -20.0, 20.0, 60.0, 100.0, 140.0, 180.0], dtype=&#x27;float64&#x27;, name=&#x27;lon&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-d20f90e1-8c1d-4be5-9af6-e9048172993b' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-d20f90e1-8c1d-4be5-9af6-e9048172993b' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'random_sample-280a407ce309bd2357d25d8acf7e02e7' (lat: 10,\n",
       "                                                                    lon: 10)> Size: 800B\n",
       "array([[9.491904e+17, 9.494496e+17, 9.492768e+17, 9.493632e+17,\n",
       "        9.492768e+17, 9.496224e+17, 9.497088e+17, 9.488448e+17,\n",
       "        9.496224e+17, 9.491040e+17],\n",
       "       [9.494496e+17, 9.491904e+17, 9.501408e+17, 9.494496e+17,\n",
       "        9.496224e+17, 9.494496e+17, 9.497088e+17, 9.491040e+17,\n",
       "        9.491040e+17, 9.493632e+17],\n",
       "       [9.496224e+17, 9.492768e+17, 9.491040e+17, 9.490176e+17,\n",
       "        9.491904e+17, 9.495360e+17, 9.491904e+17, 9.497088e+17,\n",
       "        9.489312e+17, 9.494496e+17],\n",
       "       [9.491904e+17, 9.488448e+17, 9.495360e+17, 9.493632e+17,\n",
       "        9.492768e+17, 9.497088e+17, 9.494496e+17, 9.494496e+17,\n",
       "        9.496224e+17, 9.490176e+17],\n",
       "       [9.494496e+17, 9.498816e+17, 9.493632e+17, 9.489312e+17,\n",
       "        9.494496e+17, 9.490176e+17, 9.494496e+17, 9.495360e+17,\n",
       "        9.496224e+17, 9.491040e+17],\n",
       "       [9.497088e+17, 9.492768e+17, 9.494496e+17, 9.497088e+17,\n",
       "        9.499680e+17, 9.496224e+17, 9.493632e+17, 9.490176e+17,\n",
       "        9.492768e+17, 9.493632e+17],\n",
       "       [9.493632e+17, 9.496224e+17, 9.491040e+17, 9.490176e+17,\n",
       "        9.491040e+17, 9.497088e+17, 9.491904e+17, 9.497952e+17,\n",
       "        9.497088e+17, 9.491040e+17],\n",
       "       [9.490176e+17, 9.496224e+17, 9.495360e+17, 9.490176e+17,\n",
       "        9.493632e+17, 9.491904e+17, 9.496224e+17, 9.489312e+17,\n",
       "        9.504000e+17, 9.491904e+17],\n",
       "       [9.492768e+17, 9.493632e+17, 9.489312e+17, 9.497952e+17,\n",
       "        9.497952e+17, 9.495360e+17, 9.495360e+17, 9.486720e+17,\n",
       "        9.494496e+17, 9.493632e+17],\n",
       "       [9.494496e+17, 9.494496e+17, 9.497952e+17, 9.493632e+17,\n",
       "        9.490176e+17, 9.491040e+17, 9.491040e+17, 9.493632e+17,\n",
       "        9.494496e+17, 9.491040e+17]])\n",
       "Coordinates:\n",
       "  * lat      (lat) float64 80B -90.0 -70.0 -50.0 -30.0 ... 30.0 50.0 70.0 90.0\n",
       "  * lon      (lon) float64 80B -180.0 -140.0 -100.0 -60.0 ... 100.0 140.0 180.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################\n",
    "# Function\n",
    "#############################################\n",
    "def day_cumsum_reaches_threshold_linear(\n",
    "    degree_days, start_index, start_time_values, threshold\n",
    "):\n",
    "    cumsum = np.cumsum(degree_days[start_index:])\n",
    "    threshold_reached = np.where(cumsum >= threshold)[0]\n",
    "    if len(threshold_reached) == 0:\n",
    "        print(\"error\")\n",
    "        return np.datetime64(\"NaT\", \"ns\")\n",
    "    first_reached_index = threshold_reached[0]\n",
    "    result_date = start_time_values[start_index + first_reached_index]\n",
    "    return result_date\n",
    "\n",
    "\n",
    "#############################################\n",
    "# Input data\n",
    "#############################################\n",
    "\n",
    "vday_cumsum_reaches_threshold_linear = np.vectorize(day_cumsum_reaches_threshold_linear)\n",
    "\n",
    "\n",
    "time = pd.date_range(\"2000-01-01\", periods=50, freq=\"D\").to_numpy(\n",
    "    dtype=\"datetime64[ns]\"\n",
    ")\n",
    "lat = np.linspace(-90, 90, 10)\n",
    "lon = np.linspace(-180, 180, 10)\n",
    "degree_days = xr.DataArray(\n",
    "    da.random.random((10, 10, 50), chunks=(10, 10, -1)),  # No chunking along time\n",
    "    coords=[lat, lon, time],\n",
    "    dims=[\"lat\", \"lon\", \"time\"],\n",
    ")\n",
    "start_dates = xr.DataArray(\n",
    "    np.random.choice(time[:5], size=(10, 10)), coords=[lat, lon], dims=[\"lat\", \"lon\"]\n",
    ")\n",
    "start_indices = np.array(\n",
    "    [np.where(degree_days.time.values == d)[0][0] for d in start_dates.values.flatten()]\n",
    ").reshape(start_dates.shape)\n",
    "threshold = 15\n",
    "\n",
    "#############################################\n",
    "# Apply function\n",
    "#############################################\n",
    "\n",
    "\n",
    "result_raw = xr.apply_ufunc(\n",
    "    day_cumsum_reaches_threshold_linear,\n",
    "    degree_days,\n",
    "    start_indices,\n",
    "    degree_days.time.values.astype(\"datetime64[ns]\"),\n",
    "    threshold,\n",
    "    input_core_dims=[[\"time\"], [], [\"time\"], []],\n",
    "    output_core_dims=[[]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    output_dtypes=[],\n",
    ")\n",
    "\n",
    "\n",
    "result_raw.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Define the shape\n",
    "shape = (10, 10, 100)\n",
    "\n",
    "# Create the base 2D array with the specified pattern\n",
    "base_array = np.zeros((10, 10), dtype=int)\n",
    "base_array[0, :] = np.arange(1, 11)  # First row with integers 1-10\n",
    "base_array[1, :] = 1  # Second row with all 1's\n",
    "base_array[2, :] = 2  # Third row with all 2's\n",
    "\n",
    "# Tile the base array along the time dimension to create a 3D array\n",
    "degree_days_data = np.tile(base_array[:, :, np.newaxis], (1, 1, 100))\n",
    "\n",
    "# Generate time coordinates\n",
    "time = pd.date_range(\"2000-01-01\", periods=100, freq=\"D\")\n",
    "\n",
    "# Create the xarray.DataArray\n",
    "degree_days = xr.DataArray(\n",
    "    degree_days_data,\n",
    "    coords={\n",
    "        \"latitude\": range(10),\n",
    "        \"longitude\": range(10),\n",
    "        \"t\": time,\n",
    "    },\n",
    "    dims=[\"latitude\", \"longitude\", \"t\"],\n",
    ")\n",
    "\n",
    "latitude = degree_days[\"latitude\"]\n",
    "longitude = degree_days[\"longitude\"]\n",
    "\n",
    "# Optionally, chunk the array along the specified dimensions\n",
    "degree_days = degree_days.chunk({\"latitude\": 5, \"longitude\": 5, \"t\": -1})\n",
    "##################################################################\n",
    "\n",
    "\n",
    "start_dates = xr.DataArray(\n",
    "    np.full(\n",
    "        (10, 10), np.datetime64(\"2000-01-01\", \"ns\")\n",
    "    ),  # Set all start dates to 2000-01-01\n",
    "    coords=[latitude, longitude],\n",
    "    dims=[\"latitude\", \"longitude\"],\n",
    ")\n",
    "start_indices = np.array(\n",
    "    [np.where(degree_days.t.values == d)[0][0] for d in start_dates.values.flatten()]\n",
    ").reshape(start_dates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the PRISM data\n",
    "\n",
    "# create xarray of model dates matching input shape matching start date e.g. in the xy shape of la_window_dd with coordinartes\n",
    "# of la_window_dd\n",
    "\n",
    "\n",
    "model_start_date = np.datetime64(\"2001-01-01\", \"ns\")\n",
    "\n",
    "date_array_np = np.array(\n",
    "    [\n",
    "        model_start_date\n",
    "        for i in range(la_window_dd.sizes[\"latitude\"] * la_window_dd.sizes[\"longitude\"])\n",
    "    ]\n",
    ").reshape(la_window_dd.sizes[\"latitude\"], la_window_dd.sizes[\"longitude\"])\n",
    "\n",
    "# create xarray with the same shape as la_window_dd lat/long  with only one time dimension\n",
    "date_array_xr = xr.DataArray(\n",
    "    date_array_np,\n",
    "    dims=[\"latitude\", \"longitude\"],\n",
    "    coords={\n",
    "        \"latitude\": la_window_dd[\"latitude\"],\n",
    "        \"longitude\": la_window_dd[\"longitude\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "#create start indices array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<generator object <genexpr> at 0x7bc4473cfbc0>, dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# set time to datetime64[ns]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime64[ns]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime64[ns]\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Make it into an xarray\u001b[39;00m\n\u001b[1;32m      9\u001b[0m time_array \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\n\u001b[1;32m     10\u001b[0m     time,\n\u001b[1;32m     11\u001b[0m     dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     },\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "# Create a 10x10x10 array of dates starting from January 1st, 2000\n",
    "time = pd.date_range(\"2000-01-01\", periods=10, freq=\"D\")\n",
    "# set time to datetime64[ns]\n",
    "time = time.to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "time = np.tile(time.to_numpy(dtype=\"datetime64[ns]\"), (10, 10, 1))\n",
    "\n",
    "# Make it into an xarray\n",
    "time_array = xr.DataArray(\n",
    "    time,\n",
    "    dims=[\"x\", \"y\", \"time\"],\n",
    "    coords={\n",
    "        \"x\": range(10),\n",
    "        \"y\": range(10),\n",
    "        \"time\": pd.date_range(\"2000-01-01\", periods=10, freq=\"D\"),\n",
    "    },\n",
    ")\n",
    "index = 3\n",
    "# split into 5x5x5 chunkas\n",
    "time_array = time_array.chunk({\"x\": 5, \"y\": 5})\n",
    "\n",
    "\n",
    "def demo_time_function(time_array, index):\n",
    "\n",
    "    return time_array[index]\n",
    "\n",
    "\n",
    "# Apply the function using xr.apply_ufunc\n",
    "result = xr.apply_ufunc(\n",
    "    demo_time_function,\n",
    "    time_array,\n",
    "    index,\n",
    "    input_core_dims=[[\"time\"], []],\n",
    "    output_core_dims=[[]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    output_dtypes=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 16:45:02,490 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('vectorize_demo_time_function-vectorize_demo_time_function_0-transpose-b067475339a1de5115f0b682c2eedded', 0, 0)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((subgraph_callable-53e99cb1ec57d69601bf82cfc1509450, (subgraph_callable-f47d40dae441c21700a6a4436d964c1b, (<function concatenate_axes at 0x79e0b7fc2d40>, [array([[['2000-01-01T00:00:00.000000000',\n",
      "         '2000-01-02T00:00:00.000000000',\n",
      "         '2000-01-03T00:00:00.000000000',\n",
      "         '2000-01-04T00:00:00.000000000',\n",
      "         '2000-01-05T00:00:00.000000000',\n",
      "         '2000-01-06T00:00:00.000000000',\n",
      "         '2000-01-07T00:00:00.000000000',\n",
      "         '2000-01-08T00:00:00.000000000',\n",
      "         '2000-01-09T00:00:00.000000000',\n",
      "         '2000-01-10T00:00:00.000000000'],\n",
      "        ['2000-01-01T00:00:00.000000000',\n",
      "         '2000-01-02T00:00:00.000000000',\n",
      "         '2000-01-03T00:00:00.000000000',\n",
      "         '2000-01-04T00:00:00.000000000',\n",
      "         '2000-01-05T00:00:00.000000000',\n",
      "         '2000-01-06T00:00:00.000000000',\n",
      "         '2000-01-07T00:00:00.000000000',\n",
      "         '2000-01-08T00:00:00.000000000',\n",
      "         '2000-01-09T00:00:00.000000000',\n",
      "         '2000-01-10T00:00:00.000000000'],\n",
      "  \n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\"Cannot cast NumPy timedelta64 scalar from metadata [ns] to  according to the rule \\'same_kind\\'\")'\n",
      "Traceback: '  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/optimization.py\", line 1001, in __call__\\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 157, in get\\n    result = _execute_task(task, cache)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 127, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2372, in __call__\\n    return self._call_as_normal(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2365, in _call_as_normal\\n    return self._vectorize_call(func=func, args=vargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2446, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2506, in _vectorize_call_with_signature\\n    output[index] = result\\n    ~~~~~~^^^^^^^\\n'\n",
      "\n",
      "2024-08-05 16:45:02,493 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('vectorize_demo_time_function-vectorize_demo_time_function_0-transpose-b067475339a1de5115f0b682c2eedded', 1, 0)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((subgraph_callable-53e99cb1ec57d69601bf82cfc1509450, (subgraph_callable-f47d40dae441c21700a6a4436d964c1b, (<function concatenate_axes at 0x7330c1a7ef20>, [array([[['2000-01-01T00:00:00.000000000',\n",
      "         '2000-01-02T00:00:00.000000000',\n",
      "         '2000-01-03T00:00:00.000000000',\n",
      "         '2000-01-04T00:00:00.000000000',\n",
      "         '2000-01-05T00:00:00.000000000',\n",
      "         '2000-01-06T00:00:00.000000000',\n",
      "         '2000-01-07T00:00:00.000000000',\n",
      "         '2000-01-08T00:00:00.000000000',\n",
      "         '2000-01-09T00:00:00.000000000',\n",
      "         '2000-01-10T00:00:00.000000000'],\n",
      "        ['2000-01-01T00:00:00.000000000',\n",
      "         '2000-01-02T00:00:00.000000000',\n",
      "         '2000-01-03T00:00:00.000000000',\n",
      "         '2000-01-04T00:00:00.000000000',\n",
      "         '2000-01-05T00:00:00.000000000',\n",
      "         '2000-01-06T00:00:00.000000000',\n",
      "         '2000-01-07T00:00:00.000000000',\n",
      "         '2000-01-08T00:00:00.000000000',\n",
      "         '2000-01-09T00:00:00.000000000',\n",
      "         '2000-01-10T00:00:00.000000000'],\n",
      "  \n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\"Cannot cast NumPy timedelta64 scalar from metadata [ns] to  according to the rule \\'same_kind\\'\")'\n",
      "Traceback: '  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/optimization.py\", line 1001, in __call__\\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 157, in get\\n    result = _execute_task(task, cache)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 127, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2372, in __call__\\n    return self._call_as_normal(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2365, in _call_as_normal\\n    return self._vectorize_call(func=func, args=vargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2446, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2506, in _vectorize_call_with_signature\\n    output[index] = result\\n    ~~~~~~^^^^^^^\\n'\n",
      "\n",
      "2024-08-05 16:45:02,502 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('vectorize_demo_time_function-vectorize_demo_time_function_0-transpose-b067475339a1de5115f0b682c2eedded', 1, 1)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((subgraph_callable-53e99cb1ec57d69601bf82cfc1509450, (subgraph_callable-f47d40dae441c21700a6a4436d964c1b, (<function concatenate_axes at 0x7d97566f2d40>, [array([[['2000-01-01T00:00:00.000000000',\n",
      "         '2000-01-02T00:00:00.000000000',\n",
      "         '2000-01-03T00:00:00.000000000',\n",
      "         '2000-01-04T00:00:00.000000000',\n",
      "         '2000-01-05T00:00:00.000000000',\n",
      "         '2000-01-06T00:00:00.000000000',\n",
      "         '2000-01-07T00:00:00.000000000',\n",
      "         '2000-01-08T00:00:00.000000000',\n",
      "         '2000-01-09T00:00:00.000000000',\n",
      "         '2000-01-10T00:00:00.000000000'],\n",
      "        ['2000-01-01T00:00:00.000000000',\n",
      "         '2000-01-02T00:00:00.000000000',\n",
      "         '2000-01-03T00:00:00.000000000',\n",
      "         '2000-01-04T00:00:00.000000000',\n",
      "         '2000-01-05T00:00:00.000000000',\n",
      "         '2000-01-06T00:00:00.000000000',\n",
      "         '2000-01-07T00:00:00.000000000',\n",
      "         '2000-01-08T00:00:00.000000000',\n",
      "         '2000-01-09T00:00:00.000000000',\n",
      "         '2000-01-10T00:00:00.000000000'],\n",
      "  \n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\"Cannot cast NumPy timedelta64 scalar from metadata [ns] to  according to the rule \\'same_kind\\'\")'\n",
      "Traceback: '  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/optimization.py\", line 1001, in __call__\\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 157, in get\\n    result = _execute_task(task, cache)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 127, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2372, in __call__\\n    return self._call_as_normal(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2365, in _call_as_normal\\n    return self._vectorize_call(func=func, args=vargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2446, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2506, in _vectorize_call_with_signature\\n    output[index] = result\\n    ~~~~~~^^^^^^^\\n'\n",
      "\n",
      "2024-08-05 16:45:02,508 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('vectorize_demo_time_function-vectorize_demo_time_function_0-transpose-b067475339a1de5115f0b682c2eedded', 0, 1)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((subgraph_callable-53e99cb1ec57d69601bf82cfc1509450, (subgraph_callable-f47d40dae441c21700a6a4436d964c1b, (<function concatenate_axes at 0x7d97566f2d40>, [array([[['2000-01-01T00:00:00.000000000',\n",
      "         '2000-01-02T00:00:00.000000000',\n",
      "         '2000-01-03T00:00:00.000000000',\n",
      "         '2000-01-04T00:00:00.000000000',\n",
      "         '2000-01-05T00:00:00.000000000',\n",
      "         '2000-01-06T00:00:00.000000000',\n",
      "         '2000-01-07T00:00:00.000000000',\n",
      "         '2000-01-08T00:00:00.000000000',\n",
      "         '2000-01-09T00:00:00.000000000',\n",
      "         '2000-01-10T00:00:00.000000000'],\n",
      "        ['2000-01-01T00:00:00.000000000',\n",
      "         '2000-01-02T00:00:00.000000000',\n",
      "         '2000-01-03T00:00:00.000000000',\n",
      "         '2000-01-04T00:00:00.000000000',\n",
      "         '2000-01-05T00:00:00.000000000',\n",
      "         '2000-01-06T00:00:00.000000000',\n",
      "         '2000-01-07T00:00:00.000000000',\n",
      "         '2000-01-08T00:00:00.000000000',\n",
      "         '2000-01-09T00:00:00.000000000',\n",
      "         '2000-01-10T00:00:00.000000000'],\n",
      "  \n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\"Cannot cast NumPy timedelta64 scalar from metadata [ns] to  according to the rule \\'same_kind\\'\")'\n",
      "Traceback: '  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/optimization.py\", line 1001, in __call__\\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 157, in get\\n    result = _execute_task(task, cache)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 127, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2372, in __call__\\n    return self._call_as_normal(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2365, in _call_as_normal\\n    return self._vectorize_call(func=func, args=vargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2446, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2506, in _vectorize_call_with_signature\\n    output[index] = result\\n    ~~~~~~^^^^^^^\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot cast NumPy timedelta64 scalar from metadata [ns] to  according to the rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/xarray/core/dataarray.py:1179\u001b[0m, in \u001b[0;36mDataArray.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03mremote source into memory and return a new array.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/xarray/core/dataarray.py:1147\u001b[0m, in \u001b[0;36mDataArray.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    remote source into memory and return this array.\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1147\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable \u001b[38;5;241m=\u001b[39m new\u001b[38;5;241m.\u001b[39m_variable\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/xarray/core/dataset.py:863\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m chunkmanager \u001b[38;5;241m=\u001b[39m get_chunked_array_type(\u001b[38;5;241m*\u001b[39mlazy_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, Any], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlazy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data):\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/xarray/namedarray/daskmanager.py:86\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[0;34m(self, *data, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mdata: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, _DType_co], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py:2372\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_stage_2(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_as_normal(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py:2365\u001b[0m, in \u001b[0;36m_call_as_normal\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2362\u001b[0m     vargs \u001b[38;5;241m=\u001b[39m [args[_i] \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[1;32m   2363\u001b[0m     vargs\u001b[38;5;241m.\u001b[39mextend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize_call(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39mvargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py:2446\u001b[0m, in \u001b[0;36m_vectorize_call\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Vectorized call to `func` over positional `args`.\"\"\"\u001b[39;00m\n\u001b[1;32m   2445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2446\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize_call_with_signature(func, args)\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m   2448\u001b[0m     res \u001b[38;5;241m=\u001b[39m func()\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py:2506\u001b[0m, in \u001b[0;36m_vectorize_call_with_signature\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2502\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m _create_arrays(broadcast_shape, dim_sizes,\n\u001b[1;32m   2503\u001b[0m                                  output_core_dims, otypes, results)\n\u001b[1;32m   2505\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outputs, results):\n\u001b[0;32m-> 2506\u001b[0m         output[index] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m   2508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2509\u001b[0m     \u001b[38;5;66;03m# did not call the function even once\u001b[39;00m\n\u001b[1;32m   2510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m otypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast NumPy timedelta64 scalar from metadata [ns] to  according to the rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "result = result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'compute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'compute'"
     ]
    }
   ],
   "source": [
    "result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2000-01-29T00:00:00.000000000')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.datetime64(int(foo[1][1]), \"ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04',\n",
       "       '2000-01-05', '2000-01-06', '2000-01-07', '2000-01-08',\n",
       "       '2000-01-09', '2000-01-10', '2000-01-11', '2000-01-12',\n",
       "       '2000-01-13', '2000-01-14', '2000-01-15', '2000-01-16',\n",
       "       '2000-01-17', '2000-01-18', '2000-01-19', '2000-01-20',\n",
       "       '2000-01-21', '2000-01-22', '2000-01-23', '2000-01-24',\n",
       "       '2000-01-25', '2000-01-26', '2000-01-27', '2000-01-28',\n",
       "       '2000-01-29', '2000-01-30', '2000-01-31', '2000-02-01',\n",
       "       '2000-02-02', '2000-02-03', '2000-02-04', '2000-02-05',\n",
       "       '2000-02-06', '2000-02-07', '2000-02-08', '2000-02-09',\n",
       "       '2000-02-10', '2000-02-11', '2000-02-12', '2000-02-13',\n",
       "       '2000-02-14', '2000-02-15', '2000-02-16', '2000-02-17',\n",
       "       '2000-02-18', '2000-02-19'], dtype='datetime64[D]')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = pd.date_range(\"2000-01-01\", periods=50, freq=\"D\")\n",
    "time_np = time.to_numpy(dtype=\"datetime64[D]\")\n",
    "time_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2000-01-05' '2000-01-05' '2000-01-06' '2000-01-06' '2000-01-07'\n",
      " '2000-01-08' '2000-01-10'        'NaT'        'NaT'        'NaT'\n",
      "        'NaT'        'NaT'        'NaT'        'NaT'        'NaT'\n",
      "        'NaT'        'NaT'        'NaT'        'NaT'        'NaT'\n",
      "        'NaT'        'NaT'        'NaT'        'NaT'        'NaT'\n",
      "        'NaT'        'NaT'        'NaT'        'NaT'        'NaT'\n",
      "        'NaT'        'NaT'        'NaT'        'NaT'        'NaT'\n",
      "        'NaT'        'NaT'        'NaT'        'NaT'        'NaT'\n",
      "        'NaT'        'NaT'        'NaT'        'NaT'        'NaT'\n",
      "        'NaT'        'NaT'        'NaT'        'NaT'        'NaT']\n"
     ]
    }
   ],
   "source": [
    "import dask.array as da\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def day_cumsum_reaches_threshold_linear_dask(\n",
    "    degree_days, start_index, time_values, threshold\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the date when the cumulative sum of degree_days reaches the given threshold,\n",
    "    starting from the specified start_index, using Dask for parallel processing.\n",
    "\n",
    "    Parameters:\n",
    "    - degree_days (da.Array): Dask array of degree days.\n",
    "    - start_index (da.Array): Dask array of starting indices.\n",
    "    - time_values (da.Array): Dask array of time values.\n",
    "    - threshold (float): The threshold value for cumulative sum.\n",
    "\n",
    "    Returns:\n",
    "    - da.Array: Dask array of dates when the cumulative sum reaches the threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute cumulative sum starting from the start_index\n",
    "    def compute_cumsum(degree_days, start_index):\n",
    "        cumsum = np.cumsum(degree_days[start_index:])\n",
    "        return cumsum\n",
    "\n",
    "    # Define a function to find the date when the threshold is reached\n",
    "    def find_threshold_date(degree_days, start_index, time_values, threshold):\n",
    "        cumsum = compute_cumsum(degree_days, start_index)\n",
    "        threshold_reached = np.where(cumsum >= threshold)[0]\n",
    "\n",
    "        if len(threshold_reached) == 0:\n",
    "            return np.datetime64(\n",
    "                \"NaT\"\n",
    "            )  # Return Not-a-Time if the threshold is not reached\n",
    "\n",
    "        first_reach_index = threshold_reached[0]\n",
    "        result_date = time_values[start_index + first_reach_index]\n",
    "        return np.datetime64(result_date, \"D\")\n",
    "\n",
    "    # Use Dask's map_blocks to apply the function across all chunks\n",
    "    result = da.map_blocks(\n",
    "        lambda degree_days_chunk, start_index_chunk, time_values_chunk: np.array(\n",
    "            [\n",
    "                find_threshold_date(\n",
    "                    degree_days_chunk, start_idx, time_values_chunk, threshold\n",
    "                )\n",
    "                for start_idx in start_index_chunk\n",
    "            ]\n",
    "        ),\n",
    "        degree_days,\n",
    "        start_index,\n",
    "        time_values,\n",
    "        dtype=\"datetime64[D]\",\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage with Dask\n",
    "import dask.array as da\n",
    "\n",
    "# Example data\n",
    "time_values = da.from_array(pd.date_range(\"2000-01-01\", periods=50, freq=\"D\"))\n",
    "degree_days = da.from_array(np.random.random(50), chunks=10)\n",
    "start_index = da.from_array(np.arange(50), chunks=10)\n",
    "threshold = 2  # Example threshold\n",
    "\n",
    "result = day_cumsum_reaches_threshold_linear_dask(\n",
    "    degree_days, start_index, time_values, threshold\n",
    ")\n",
    "print(result.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 13:26:44,701 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('vectorize_day_cumsum_reaches_threshold-vectorize_day_cumsum_reaches_threshold_0-transpose-1b099fadfcb9a00af744e8f24--60a', 1, 0)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((subgraph_callable-8545799b656b41ceee0012e91c241be1, (subgraph_callable-1443e4bc1f93a67dc47c024f981b3cbe, (<function concatenate_axes at 0x7dffb493c0e0>, [array([[[0.23695819, 0.019066  , 0.01263238, 0.05629709, 0.5644703 ,\n",
      "         0.82097152, 0.267617  , 0.17813238, 0.09494849, 0.36181699],\n",
      "        [0.95704247, 0.49117351, 0.21995795, 0.83107688, 0.20602493,\n",
      "         0.43727969, 0.1819227 , 0.89562084, 0.71185332, 0.56684085],\n",
      "        [0.86954467, 0.96298727, 0.10294405, 0.74761762, 0.89093795,\n",
      "         0.11153684, 0.55813579, 0.35962515, 0.49234164, 0.0621894 ],\n",
      "        [0.2724583 , 0.64912999, 0.49322174, 0.52635799, 0.02363424,\n",
      "         0.04032899, 0.75389124, 0.35406253, 0.01350004, 0.16435251],\n",
      "        [0.60162938, 0.86971342, 0.94666396, 0.79824104, 0.56304383,\n",
      "         0.92368605, 0.02882381, 0.15915467, 0.30391428, 0.14141547]],\n",
      "\n",
      "       [[0.26092872, 0.71634805, 0.85199093, 0.61989779, 0.78413778,\n",
      "         0.78677033, 0.74929234, 0.1108657 , 0.61081322, 0.67808043],\n",
      "        \n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\"day_cumsum_reaches_threshold() missing 1 required positional argument: \\'time_coords\\'\")'\n",
      "Traceback: '  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/optimization.py\", line 1001, in __call__\\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 157, in get\\n    result = _execute_task(task, cache)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 127, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2372, in __call__\\n    return self._call_as_normal(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2365, in _call_as_normal\\n    return self._vectorize_call(func=func, args=vargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2446, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2486, in _vectorize_call_with_signature\\n    results = func(*(arg[index] for arg in args))\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n'\n",
      "\n",
      "2024-08-14 13:26:44,705 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('vectorize_day_cumsum_reaches_threshold-vectorize_day_cumsum_reaches_threshold_0-transpose-1b099fadfcb9a00af744e8f24--60a', 1, 1)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((subgraph_callable-8545799b656b41ceee0012e91c241be1, (subgraph_callable-1443e4bc1f93a67dc47c024f981b3cbe, (<function concatenate_axes at 0x7af8dc728220>, [array([[[0.81447046, 0.94514911, 0.74109757, 0.09398822, 0.04206707,\n",
      "         0.59641741, 0.99064787, 0.38433252, 0.47401198, 0.86563172],\n",
      "        [0.84575537, 0.35642013, 0.39915698, 0.59999355, 0.44518252,\n",
      "         0.40447093, 0.98120929, 0.8609586 , 0.8772986 , 0.28931952],\n",
      "        [0.06783228, 0.05750186, 0.25983979, 0.67696776, 0.83457092,\n",
      "         0.13484096, 0.58591724, 0.82933635, 0.21353652, 0.2474686 ],\n",
      "        [0.44307897, 0.45669719, 0.18748779, 0.41672977, 0.30034351,\n",
      "         0.52104929, 0.25780195, 0.78819519, 0.51021286, 0.27161612],\n",
      "        [0.60934731, 0.58736061, 0.24405966, 0.53696425, 0.10773809,\n",
      "         0.68089365, 0.46497904, 0.38888056, 0.96903683, 0.6077918 ]],\n",
      "\n",
      "       [[0.12678162, 0.81256646, 0.38444007, 0.51862341, 0.40378304,\n",
      "         0.09395238, 0.09647304, 0.20613806, 0.9484699 , 0.5520607 ],\n",
      "        \n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\"day_cumsum_reaches_threshold() missing 1 required positional argument: \\'time_coords\\'\")'\n",
      "Traceback: '  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/optimization.py\", line 1001, in __call__\\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 157, in get\\n    result = _execute_task(task, cache)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 127, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2372, in __call__\\n    return self._call_as_normal(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2365, in _call_as_normal\\n    return self._vectorize_call(func=func, args=vargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2446, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2486, in _vectorize_call_with_signature\\n    results = func(*(arg[index] for arg in args))\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n'\n",
      "\n",
      "2024-08-14 13:26:44,708 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('vectorize_day_cumsum_reaches_threshold-vectorize_day_cumsum_reaches_threshold_0-transpose-1b099fadfcb9a00af744e8f24--60a', 0, 1)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((subgraph_callable-8545799b656b41ceee0012e91c241be1, (subgraph_callable-1443e4bc1f93a67dc47c024f981b3cbe, (<function concatenate_axes at 0x7de80d134220>, [array([[[5.01693351e-01, 3.80346358e-01, 7.70727721e-01, 8.71168052e-01,\n",
      "         3.94466345e-01, 3.37447717e-03, 3.99386229e-02, 7.25122834e-01,\n",
      "         8.32505206e-01, 4.68135793e-01],\n",
      "        [1.16167511e-01, 5.74295328e-01, 5.36931617e-01, 5.96442560e-01,\n",
      "         9.79060819e-01, 1.01869799e-01, 9.26315911e-01, 8.04214434e-01,\n",
      "         2.34310211e-01, 3.21331600e-01],\n",
      "        [5.76510489e-01, 8.23997608e-01, 8.36317272e-01, 3.28609607e-01,\n",
      "         5.53136411e-01, 4.29490256e-01, 8.48938196e-01, 6.55213060e-01,\n",
      "         3.40533155e-01, 6.65953028e-01],\n",
      "        [6.30769721e-01, 2.06252065e-01, 9.14817376e-01, 7.12967485e-02,\n",
      "         7.50857513e-01, 5.42759787e-01, 3.91867237e-01, 4.44444776e-01,\n",
      "         9.71546551e-01, 3.79619090e-01],\n",
      "        [3.45472274e-01, 8.91884559e-01, 4.90198529e-01, 2.88885539e-02,\n",
      "         9.67168603\n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\"day_cumsum_reaches_threshold() missing 1 required positional argument: \\'time_coords\\'\")'\n",
      "Traceback: '  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/optimization.py\", line 1001, in __call__\\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 157, in get\\n    result = _execute_task(task, cache)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 127, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2372, in __call__\\n    return self._call_as_normal(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2365, in _call_as_normal\\n    return self._vectorize_call(func=func, args=vargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2446, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2486, in _vectorize_call_with_signature\\n    results = func(*(arg[index] for arg in args))\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n'\n",
      "\n",
      "2024-08-14 13:26:44,715 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('vectorize_day_cumsum_reaches_threshold-vectorize_day_cumsum_reaches_threshold_0-transpose-1b099fadfcb9a00af744e8f24--60a', 0, 0)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((subgraph_callable-8545799b656b41ceee0012e91c241be1, (subgraph_callable-1443e4bc1f93a67dc47c024f981b3cbe, (<function concatenate_axes at 0x7de80d134220>, [array([[[0.65554364, 0.18217766, 0.18481483, 0.11200627, 0.2442093 ,\n",
      "         0.74037137, 0.76956388, 0.98624255, 0.89391994, 0.34407559],\n",
      "        [0.57448493, 0.50650089, 0.14600422, 0.14119357, 0.47937438,\n",
      "         0.25241592, 0.37488375, 0.86781037, 0.31867242, 0.02275148],\n",
      "        [0.51240574, 0.54417382, 0.67838089, 0.60039524, 0.41681148,\n",
      "         0.40422895, 0.24802608, 0.60290938, 0.09234092, 0.69097394],\n",
      "        [0.61542769, 0.17656192, 0.98085429, 0.59506739, 0.58936781,\n",
      "         0.97180415, 0.92805255, 0.29292008, 0.78857212, 0.25694406],\n",
      "        [0.68031598, 0.3000517 , 0.72460734, 0.61146982, 0.17457501,\n",
      "         0.56383086, 0.20759175, 0.26721178, 0.13502831, 0.34378581]],\n",
      "\n",
      "       [[0.72622224, 0.65121512, 0.84167381, 0.98909129, 0.07497945,\n",
      "         0.17077795, 0.54177237, 0.31621039, 0.25285578, 0.42615815],\n",
      "        \n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\"day_cumsum_reaches_threshold() missing 1 required positional argument: \\'time_coords\\'\")'\n",
      "Traceback: '  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/optimization.py\", line 1001, in __call__\\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 157, in get\\n    result = _execute_task(task, cache)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/core.py\", line 127, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2372, in __call__\\n    return self._call_as_normal(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2365, in _call_as_normal\\n    return self._vectorize_call(func=func, args=vargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2446, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/thom/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py\", line 2486, in _vectorize_call_with_signature\\n    results = func(*(arg[index] for arg in args))\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "day_cumsum_reaches_threshold() missing 1 required positional argument: 'time_coords'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m result \u001b[38;5;241m=\u001b[39m apply_cumsum_threshold(degree_days, start_day, threshold)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Compute the result\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m computed_result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(computed_result)\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/xarray/core/dataarray.py:1179\u001b[0m, in \u001b[0;36mDataArray.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03mremote source into memory and return a new array.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/xarray/core/dataarray.py:1147\u001b[0m, in \u001b[0;36mDataArray.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    remote source into memory and return this array.\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1147\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable \u001b[38;5;241m=\u001b[39m new\u001b[38;5;241m.\u001b[39m_variable\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/xarray/core/dataset.py:863\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m chunkmanager \u001b[38;5;241m=\u001b[39m get_chunked_array_type(\u001b[38;5;241m*\u001b[39mlazy_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, Any], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlazy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data):\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/xarray/namedarray/daskmanager.py:86\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[0;34m(self, *data, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mdata: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, _DType_co], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py:2372\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_stage_2(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_as_normal(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py:2365\u001b[0m, in \u001b[0;36m_call_as_normal\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2362\u001b[0m     vargs \u001b[38;5;241m=\u001b[39m [args[_i] \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[1;32m   2363\u001b[0m     vargs\u001b[38;5;241m.\u001b[39mextend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize_call(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39mvargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py:2446\u001b[0m, in \u001b[0;36m_vectorize_call\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Vectorized call to `func` over positional `args`.\"\"\"\u001b[39;00m\n\u001b[1;32m   2445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2446\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize_call_with_signature(func, args)\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m   2448\u001b[0m     res \u001b[38;5;241m=\u001b[39m func()\n",
      "File \u001b[0;32m~/miniforge3/envs/fruitflypheno_hdf5/lib/python3.12/site-packages/numpy/lib/function_base.py:2486\u001b[0m, in \u001b[0;36m_vectorize_call_with_signature\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2483\u001b[0m nout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output_core_dims)\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndindex(\u001b[38;5;241m*\u001b[39mbroadcast_shape):\n\u001b[0;32m-> 2486\u001b[0m     results \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m(arg[index] \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[1;32m   2488\u001b[0m     n_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nout \u001b[38;5;241m!=\u001b[39m n_results:\n",
      "\u001b[0;31mTypeError\u001b[0m: day_cumsum_reaches_threshold() missing 1 required positional argument: 'time_coords'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def day_cumsum_reaches_threshold(degree_days, time_coords, start_day, threshold):\n",
    "    # Perform cumulative sum and threshold check\n",
    "    cumsum = np.cumsum(degree_days[start_day:], axis=-1)\n",
    "    threshold_reached = np.where(cumsum >= threshold)[0]\n",
    "\n",
    "    # Check if the threshold was reached\n",
    "    if len(threshold_reached) == 0:\n",
    "        return np.datetime64(\"NaT\")  # Return Not-a-Time if the threshold is not reached\n",
    "\n",
    "    # Compute the date when the threshold was first reached\n",
    "    date_index = threshold_reached[0]\n",
    "    date = np.datetime64(time_coords[start_day + date_index], \"D\")\n",
    "    print(date)\n",
    "    return date\n",
    "\n",
    "\n",
    "# Example of applying the function over a larger dataset with Dask\n",
    "def apply_cumsum_threshold(dataset, start_day, threshold):\n",
    "    result = xr.apply_ufunc(\n",
    "        day_cumsum_reaches_threshold,\n",
    "        dataset,\n",
    "        input_core_dims=[[\"t\"]],\n",
    "        output_core_dims=[[]],\n",
    "        vectorize=True,\n",
    "        dask=\"parallelized\",\n",
    "        kwargs={\"start_day\": start_day, \"threshold\": threshold},\n",
    "        output_dtypes=[np.datetime64],\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "# Create a sample dataset with Dask\n",
    "lat = np.arange(10)\n",
    "lon = np.arange(10)\n",
    "time = pd.date_range(\"2000-01-01\", periods=10)\n",
    "data = np.random.rand(10, 10, 10)\n",
    "degree_days = xr.DataArray(data, coords=[lat, lon, time], dims=[\"lat\", \"lon\", \"t\"])\n",
    "# Convert to a Dask array\n",
    "degree_days = degree_days.chunk({\"lat\": 5, \"lon\": 5})\n",
    "\n",
    "start_day = 0  # example start day\n",
    "threshold = 5  # example threshold\n",
    "\n",
    "# Apply the function over the larger dataset\n",
    "result = apply_cumsum_threshold(degree_days, start_day, threshold)\n",
    "\n",
    "# Compute the result\n",
    "computed_result = result.compute()\n",
    "print(computed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of start dates for each year from 2000 to 2008\n",
    "start_dates = []\n",
    "model_month = 1\n",
    "model_day = 1\n",
    "for year in range(2000, 2009):\n",
    "    start_dates.append(datetime.datetime(year, model_month, model_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 15\n",
    "\n",
    "# Compute the day when cumulative sum reaches the threshold starting from day 1\n",
    "start_day = \"2001-01-06\"\n",
    "day_reach_threshold_from_start = day_cumsum_reaches_threshold(\n",
    "    la_window_dd, start_day, threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la_combined_DD[\"degree_days\"].isel(t=slice(4, None))\n",
    "# repeat but use .sel for date 01-03-2001\n",
    "la_combined_DD[\"degree_days\"].sel(t=slice(\"2001-01-03\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_degree_days(tmax, tmin, base_temp=10):\n",
    "    \"\"\"\n",
    "    Calculate degree days from tmax and tmin.\n",
    "    Degree days = (tmax + tmin) / 2 - base_temp\n",
    "    \"\"\"\n",
    "    mean_temp = (tmax + tmin) / 2\n",
    "    degree_days = mean_temp - base_temp\n",
    "    return degree_days\n",
    "\n",
    "\n",
    "def process_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Apply degree days calculation and drop tmax and tmin variables.\n",
    "    \"\"\"\n",
    "    # Directly access tmax and tmin\n",
    "    tmax = dataset[\"tmax\"]\n",
    "    tmin = dataset[\"tmin\"]\n",
    "\n",
    "    # Print dimensions and coordinates for debugging\n",
    "    print(\"Dimensions of tmax:\", tmax.dims)\n",
    "    print(\"Dimensions of tmin:\", tmin.dims)\n",
    "    print(\"Coordinates of dataset:\", dataset.coords)\n",
    "\n",
    "    # Calculate degree days using apply_ufunc\n",
    "    degree_days = xr.apply_ufunc(\n",
    "        single_sine_horizontal_cutoff,\n",
    "        tmax,\n",
    "        tmin,\n",
    "        input_core_dims=[[\"t\"], [\"t\"]],\n",
    "        output_core_dims=[[\"t\"]],  # No core dimensions for the output\n",
    "        vectorize=True,\n",
    "        dask=\"allowed\",  # Ensure compatibility with dask\n",
    "        output_dtypes=[float],  # Specify output data type\n",
    "    )\n",
    "\n",
    "    # Print dimensions of degree_days for debugging\n",
    "    print(\"Dimensions of degree_days:\", degree_days.dims)\n",
    "\n",
    "    # Create a new DataArray with the degree days\n",
    "    degree_days_da = xr.DataArray(\n",
    "        degree_days,\n",
    "        dims=[\"time\"],  # Use 'time' dimension for the DataArray\n",
    "        coords={\n",
    "            \"time\": dataset[\"time\"].values\n",
    "        },  # Use 'time' coordinate from the original dataset\n",
    "        name=\"degree_days\",\n",
    "    )\n",
    "\n",
    "    # Add degree days to the dataset and drop tmax and tmin\n",
    "    dataset = dataset.assign(degree_days=degree_days_da)\n",
    "    dataset = dataset.drop_vars([\"tmax\", \"tmin\"])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Example usage\n",
    "base_dir = data_path\n",
    "start_year = 2000\n",
    "end_year = 2020\n",
    "start_day = 1\n",
    "end_day = 10\n",
    "\n",
    "combined_dataset = load_and_concatenate_datasets(\n",
    "    start_year, end_year, start_day, end_day, base_dir\n",
    ")\n",
    "\n",
    "# Process the dataset\n",
    "processed_dataset = process_dataset(combined_dataset)\n",
    "\n",
    "# Persist or compute if needed\n",
    "processed_dataset = processed_dataset.persist()\n",
    "\n",
    "# Subset dataset by coordinates\n",
    "la_combined = subset_dataset_by_coords(processed_dataset, 34.05, -118.25)\n",
    "\n",
    "# Print dataset information\n",
    "print(la_combined)\n",
    "print(la_combined.dims)\n",
    "print(la_combined.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from dask import array as da\n",
    "\n",
    "\n",
    "def process_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Apply degree days calculation and drop tmax and tmin variables.\n",
    "    \"\"\"\n",
    "    # Ensure tmax and tmin are dask arrays\n",
    "    tmax = dataset[\"tmax\"]\n",
    "    tmin = dataset[\"tmin\"]\n",
    "\n",
    "    # Calculate degree days using map_blocks\n",
    "    degree_days = da.map_blocks(\n",
    "        lambda tmax, tmin: single_sine_horizontal_cutoff(tmax, tmin),\n",
    "        tmax,\n",
    "        tmin,\n",
    "        dtype=float,\n",
    "    )\n",
    "\n",
    "    # Create a new DataArray with the degree days\n",
    "    degree_days_da = xr.DataArray(degree_days, dims=dataset.dims, coords=dataset.coords)\n",
    "\n",
    "    # Add degree days to the dataset and drop tmax and tmin\n",
    "    dataset = dataset.assign(degree_days=degree_days_da)\n",
    "    dataset = dataset.drop_vars([\"tmax\", \"tmin\"])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Process the dataset\n",
    "processed_la = process_dataset(la_combined)\n",
    "\n",
    "processed_la = processed_la.compute()\n",
    "# Subset dataset by coordinates\n",
    "\n",
    "# Print dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from dask import array as da\n",
    "\n",
    "\n",
    "def calculate_degree_days(tmax, tmin, base_temp=10):\n",
    "    \"\"\"\n",
    "    Calculate degree days from tmax and tmin.\n",
    "    Degree days = (tmax + tmin) / 2 - base_temp\n",
    "    \"\"\"\n",
    "    mean_temp = (tmax + tmin) / 2\n",
    "    degree_days = mean_temp - base_temp\n",
    "    return degree_days\n",
    "\n",
    "\n",
    "def process_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Apply degree days calculation and drop tmax and tmin variables.\n",
    "    \"\"\"\n",
    "    # Directly access tmax and tmin\n",
    "    tmax = dataset[\"tmax\"]\n",
    "    tmin = dataset[\"tmin\"]\n",
    "\n",
    "    # Calculate degree days\n",
    "    degree_days = xr.apply_ufunc(\n",
    "        calculate_degree_days,\n",
    "        tmax,\n",
    "        tmin,\n",
    "        input_core_dims=[[\"time\"], [\"time\"]],\n",
    "        output_core_dims=[[\"time\"]],\n",
    "        vectorize=True,\n",
    "        dask=\"allowed\",  # Ensure compatibility with dask\n",
    "    )\n",
    "\n",
    "    # Create a new DataArray with the degree days\n",
    "    degree_days_da = xr.DataArray(\n",
    "        degree_days,\n",
    "        dims=dataset.dims,  # Use dimensions from the original dataset\n",
    "        coords=dataset.coords,  # Use coordinates from the original dataset\n",
    "        name=\"degree_days\",\n",
    "    )\n",
    "\n",
    "    # Add degree days to the dataset and drop tmax and tmin\n",
    "    dataset = dataset.assign(degree_days=degree_days_da)\n",
    "    dataset = dataset.drop_vars([\"tmax\", \"tmin\"])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "processed_dataset = process_dataset(la_combined)\n",
    "\n",
    "# Persist or compute if needed\n",
    "processed_dataset = processed_dataset.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(la_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np\n",
    "\n",
    "# Define the shape of the array\n",
    "lat, lon = 10, 10\n",
    "days_per_year = 365\n",
    "years = 2\n",
    "variables = 2  # tmean and tmax\n",
    "total_days = days_per_year * years\n",
    "\n",
    "# Create larger random data for tmean and tmax to ensure cumulative sum can reach 50\n",
    "tmean_data = np.random.rand(total_days, lat, lon) * 10\n",
    "tmax_data = np.random.rand(total_days, lat, lon) * 10\n",
    "\n",
    "# Stack the data along a new axis to create a single array\n",
    "data = np.stack([tmean_data, tmax_data], axis=0)  # Shape will be (variables, total_days, lat, lon)\n",
    "\n",
    "# Convert the numpy array to a dask array\n",
    "dask_array = da.from_array(data, chunks=(variables, days_per_year//4, lat//2, lon//2))  # Adjust chunks as needed\n",
    "\n",
    "# Add one to every day for each variable\n",
    "dask_array_plus_one = dask_array + 1\n",
    "\n",
    "# Split the array into separate years\n",
    "dask_array_years = [dask_array_plus_one[:, i*days_per_year:(i+1)*days_per_year, :, :] for i in range(years)]\n",
    "\n",
    "# Calculate the cumulative sum along the time (days) axis for each year\n",
    "cumsum_arrays = [da.cumsum(year, axis=1) for year in dask_array_years]\n",
    "\n",
    "# Function to find the first day when the cumulative sum is >= 50\n",
    "def find_day_where_cumsum_is_50(cumsum_slice):\n",
    "    condition_met = (cumsum_slice >= 50)\n",
    "    if condition_met.any():\n",
    "        return condition_met.argmax(axis=0)\n",
    "    else:\n",
    "        # Return days_per_year if the condition is never met\n",
    "        return days_per_year * np.ones_like(cumsum_slice[0], dtype=int)\n",
    "\n",
    "# Apply the function along the days axis (axis=1) for each year's cumulative sum\n",
    "days_reaching_50_each_year = [da.apply_along_axis(find_day_where_cumsum_is_50, 1, cumsum) for cumsum in cumsum_arrays]\n",
    "\n",
    "# Stack the results to get an array of shape (years, variables, lat, lon)\n",
    "days_reaching_50_result = da.stack(days_reaching_50_each_year)\n",
    "\n",
    "# Compute the result\n",
    "days_reaching_50_result_computed = days_reaching_50_result.compute()\n",
    "\n",
    "# Verification: Check some values from the result\n",
    "print(\"Shape of days_reaching_50_result_computed:\", days_reaching_50_result_computed.shape)\n",
    "print(\"Days reaching 50 for tmean (variable 0) in year 1:\")\n",
    "print(days_reaching_50_result_computed[0, 0])\n",
    "print(\"\\nDays reaching 50 for tmax (variable 1) in year 1:\")\n",
    "print(days_reaching_50_result_computed[0, 1])\n",
    "print(\"\\nDays reaching 50 for tmean (variable 0) in year 2:\")\n",
    "print(days_reaching_50_result_computed[1, 0])\n",
    "print(\"\\nDays reaching 50 for tmax (variable 1) in year 2:\")\n",
    "print(days_reaching_50_result_computed[1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = nc.Dataset(\"data/test/derived/PRISM_mean_2000-2020.nc\", \"r\", format=\"NETCDF4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take mean of netcdf \"data/test/PRISM/2020/PRISM_combo_20200101.nc\"\n",
    "\n",
    "# Open the NetCDF file\n",
    "dataset = nc.Dataset(\"data/test/PRISM/2020/PRISM_combo_20200101.nc\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nc.Dataset(\"data/test/PRISM/2020/PRISM_combo_20200101.nc\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "\n",
    "def compute(x):\n",
    "    time.sleep(2)  # Simulate a time-consuming computation\n",
    "    return x * x\n",
    "\n",
    "\n",
    "def main():\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Submit tasks to the executor\n",
    "        futures = [executor.submit(compute, i) for i in range(5)]\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()  # This blocks until the result is available\n",
    "            print(f\"Result: {result}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_values_from_ncdf(file_path, coord, variables):\n",
    "    \"\"\"\n",
    "    Extract values at a given coordinate from specified variables in a NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the NetCDF file.\n",
    "    - coord (tuple): Tuple of (latitude, longitude) for the target coordinate.\n",
    "    - variables (list): List of variable names to extract.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with variable names as keys and extracted values as values.\n",
    "    \"\"\"\n",
    "    target_lat, target_lon = coord\n",
    "\n",
    "    with nc.Dataset(file_path, \"r\") as dataset:\n",
    "        # Get the latitude and longitude variables\n",
    "        lat = dataset.variables[\"latitude\"][:]\n",
    "        lon = dataset.variables[\"longitude\"][:]\n",
    "\n",
    "        # Find the nearest indices for the given coordinates\n",
    "        lat_idx = np.abs(lat - target_lat).argmin()\n",
    "        lon_idx = np.abs(lon - target_lon).argmin()\n",
    "\n",
    "        # Extract values for each variable\n",
    "        values = tuple(\n",
    "            dataset.variables[var][0, lat_idx, lon_idx].data.item() for var in variables\n",
    "        )\n",
    "        # note to potentially clip NCDF values\n",
    "    return values\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"data/test/PRISM/2020/PRISM_combo_20200101.nc\"\n",
    "coord = (34.05, -118.25)\n",
    "variables = [\"tmin\", \"tmax\"]\n",
    "values = extract_values_from_ncdf(file_path, coord, variables)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_values(file_path, coord, variables):\n",
    "    target_lat, target_lon = coord\n",
    "\n",
    "    with nc.Dataset(file_path, \"r\") as dataset:\n",
    "        lat = dataset.variables[\"latitude\"][:]\n",
    "        lon = dataset.variables[\"longitude\"][:]\n",
    "\n",
    "        lat_idx = np.abs(lat - target_lat).argmin()\n",
    "        lon_idx = np.abs(lon - target_lon).argmin()\n",
    "\n",
    "        values = tuple(\n",
    "            dataset.variables[var][0, lat_idx, lon_idx].data.item() for var in variables\n",
    "        )\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "def process_day(file_path, coord, variables, LTT, UTT):\n",
    "    tmin, tmax = extract_values(file_path, coord, variables)\n",
    "    return single_sine_horizontal_cutoff(tmin, tmax, LTT, UTT)\n",
    "\n",
    "\n",
    "def process_days_concurrently(file_path, coord, variables, LTT, UTT, dates):\n",
    "    results = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for date in dates:\n",
    "            # Submit the process_day task to the executor\n",
    "            future = executor.submit(process_day, file_path, coord, variables, LTT, UTT)\n",
    "            futures.append(future)\n",
    "\n",
    "        # Collect results as they complete\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            results.append(future.result())\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_path = \"your_file.nc\"\n",
    "coord = (34.05, -118.25)\n",
    "variables = [\"tmin\", \"tmax\"]\n",
    "LTT = 10\n",
    "UTT = 20\n",
    "dates = [\"2024-07-01\", \"2024-07-02\", \"2024-07-03\"]\n",
    "\n",
    "results = process_days_concurrently(file_path, coord, variables, LTT, UTT, dates)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_file_path_PRISM(year, month, day, base_dir):\n",
    "    \n",
    "    \n",
    "    file_path = f\"{base_dir}/{year}/PRISM_combo_{year}{month}{day}.nc\"\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def extract_values(file_path, coord, variables):\n",
    "    target_lat, target_lon = coord\n",
    "\n",
    "    with nc.Dataset(file_path, \"r\") as dataset:\n",
    "        lat = dataset.variables[\"latitude\"][:]\n",
    "        lon = dataset.variables[\"longitude\"][:]\n",
    "\n",
    "        lat_idx = np.abs(lat - target_lat).argmin()\n",
    "        lon_idx = np.abs(lon - target_lon).argmin()\n",
    "\n",
    "        values = tuple(\n",
    "            dataset.variables[var][0, lat_idx, lon_idx].data.item() for var in variables\n",
    "        )\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "def process_days(start_date, coord, variables, LTT, UTT, target_GDD_value):\n",
    "    accumulated_GDD_result = 0\n",
    "    \n",
    "    data_date = start_date\n",
    "    while accumulated_GDD_result < target_GDD_value:\n",
    "        date_path = get_file_path_PRISM(data_date.year, data_date.month, data_date.day, \"data/test/PRISM/\")\n",
    "\n",
    "        tmin, tmax = extract_values(file_path, coord, variables)\n",
    "        daily_result = single_sine_horizontal_cutoff(tmin, tmax, LTT, UTT)\n",
    "        accumulated_GDD_result += daily_result\n",
    "        \n",
    "\n",
    "        \n",
    "    return accumulated_result, total_days_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_file_paths(2020, \"01\", \"01\", \"data/test/PRISM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Open the NetCDF file\n",
    "\n",
    "# Get the latitude and longitude variables\n",
    "lat = dataset.variables[\"latitude\"][:]\n",
    "lon = dataset.variables[\"longitude\"][:]\n",
    "\n",
    "# Get the data variable (e.g., temperature)\n",
    "data = dataset.variables[\"tmax\"][:]\n",
    "\n",
    "# Your target coordinate\n",
    "target_lat = 34.05  # example latitude\n",
    "target_lon = -118.25  # example longitude\n",
    "\n",
    "# Find the nearest indices for the given coordinates\n",
    "lat_idx = np.abs(lat - target_lat).argmin()\n",
    "lon_idx = np.abs(lon - target_lon).argmin()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.add_feature(cfeature.BORDERS)\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "\n",
    "# Plot the data as a contourf plot\n",
    "plt.contourf(lon, lat, data[0, :, :], transform=ccrs.PlateCarree(), cmap=\"coolwarm\")\n",
    "plt.colorbar(label=\"Temperature\")\n",
    "\n",
    "# Plot the target point\n",
    "plt.plot(target_lon, target_lat, \"bo\", markersize=10, transform=ccrs.PlateCarree())\n",
    "plt.text(target_lon + 0.5, target_lat, \"Target Point\", transform=ccrs.PlateCarree())\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Temperature Map with Target Point\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Close the dataset\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np\n",
    "\n",
    "# Define the shape of the array\n",
    "lat, lon = 10, 10\n",
    "days_per_year = 365\n",
    "years = 2\n",
    "variables = 2  # tmean and tmax\n",
    "total_days = days_per_year * years\n",
    "\n",
    "# Create larger random data for tmean and tmax to ensure cumulative sum can reach 50\n",
    "tmean_data = np.random.rand(total_days, lat, lon) * 10\n",
    "tmax_data = np.random.rand(total_days, lat, lon) * 10\n",
    "\n",
    "# Stack the data along a new axis to create a single array\n",
    "data = np.stack(\n",
    "    [tmean_data, tmax_data], axis=0\n",
    ")  # Shape will be (variables, total_days, lat, lon)\n",
    "\n",
    "# Convert the numpy array to a dask array\n",
    "dask_array = da.from_array(\n",
    "    data, chunks=(variables, days_per_year // 4, lat // 2, lon // 2)\n",
    ")  # Adjust chunks as needed\n",
    "\n",
    "# Add one to every day for each variable\n",
    "dask_array_plus_one = dask_array + 1\n",
    "\n",
    "# Split the array into separate years\n",
    "dask_array_years = [\n",
    "    dask_array_plus_one[:, i * days_per_year : (i + 1) * days_per_year, :, :]\n",
    "    for i in range(years)\n",
    "]\n",
    "\n",
    "# Calculate the cumulative sum along the time (days) axis for each year\n",
    "cumsum_arrays = [da.cumsum(year, axis=1) for year in dask_array_years]\n",
    "\n",
    "\n",
    "# Function to find the first day when the cumulative sum is >= 50\n",
    "def find_day_where_cumsum_is_50(cumsum_slice):\n",
    "    condition_met = cumsum_slice >= 50\n",
    "    if condition_met.any():\n",
    "        return condition_met.argmax(axis=0)\n",
    "    else:\n",
    "        # Return days_per_year if the condition is never met\n",
    "        return days_per_year * np.ones_like(cumsum_slice[0], dtype=int)\n",
    "\n",
    "\n",
    "# Apply the function along the days axis (axis=1) for each year's cumulative sum\n",
    "days_reaching_50_each_year = [\n",
    "    da.apply_along_axis(find_day_where_cumsum_is_50, 1, cumsum)\n",
    "    for cumsum in cumsum_arrays\n",
    "]\n",
    "\n",
    "# Stack the results to get an array of shape (years, variables, lat, lon)\n",
    "days_reaching_50_result = da.stack(days_reaching_50_each_year)\n",
    "\n",
    "# Compute the result\n",
    "days_reaching_50_result_computed = days_reaching_50_result.compute()\n",
    "\n",
    "# Verification: Check some values from the result\n",
    "print(\n",
    "    \"Shape of days_reaching_50_result_computed:\", days_reaching_50_result_computed.shape\n",
    ")\n",
    "print(\"Days reaching 50 for tmean (variable 0) in year 1:\")\n",
    "print(days_reaching_50_result_computed[0, 0])\n",
    "print(\"\\nDays reaching 50 for tmax (variable 1) in year 1:\")\n",
    "print(days_reaching_50_result_computed[0, 1])\n",
    "print(\"\\nDays reaching 50 for tmean (variable 0) in year 2:\")\n",
    "print(days_reaching_50_result_computed[1, 0])\n",
    "print(\"\\nDays reaching 50 for tmax (variable 1) in year 2:\")\n",
    "print(days_reaching_50_result_computed[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np\n",
    "\n",
    "# Define the shape of the array\n",
    "lat, lon = 10, 10\n",
    "days_per_year = 365\n",
    "years = 2\n",
    "variables = 2  # tmean and tmax\n",
    "total_days = days_per_year * years\n",
    "\n",
    "# Create larger random data for tmean and tmax to ensure cumulative sum can reach 50\n",
    "tmean_data = np.random.rand(total_days, lat, lon) * 10\n",
    "tmax_data = np.random.rand(total_days, lat, lon) * 10\n",
    "\n",
    "# Stack the data along a new axis to create a single array\n",
    "data = np.stack(\n",
    "    [tmean_data, tmax_data], axis=0\n",
    ")  # Shape will be (variables, total_days, lat, lon)\n",
    "\n",
    "# Convert the numpy array to a dask array\n",
    "dask_array = da.from_array(\n",
    "    data, chunks=(variables, days_per_year // 4, lat // 2, lon // 2)\n",
    ")  # Adjust chunks as needed\n",
    "\n",
    "# Add one to every day for each variable\n",
    "dask_array_plus_one = dask_array + 1\n",
    "\n",
    "# Split the array into separate years\n",
    "dask_array_years = [\n",
    "    dask_array_plus_one[:, i * days_per_year : (i + 1) * days_per_year, :, :]\n",
    "    for i in range(years)\n",
    "]\n",
    "\n",
    "# Calculate the cumulative sum along the time (days) axis for each year\n",
    "cumsum_arrays = [da.cumsum(year, axis=1) for year in dask_array_years]\n",
    "\n",
    "\n",
    "# Function to find the first day when the cumulative sum is >= 50\n",
    "def find_day_where_cumsum_is_50(cumsum_slice):\n",
    "    condition_met = cumsum_slice >= 50\n",
    "    if condition_met.any():\n",
    "        return condition_met.argmax(axis=0)\n",
    "    else:\n",
    "        # Return days_per_year if the condition is never met\n",
    "        return days_per_year * np.ones_like(cumsum_slice[0], dtype=int)\n",
    "\n",
    "\n",
    "# Apply the function along the days axis (axis=1) for each year's cumulative sum\n",
    "days_reaching_50_each_year = [\n",
    "    da.apply_along_axis(find_day_where_cumsum_is_50, 1, cumsum)\n",
    "    for cumsum in cumsum_arrays\n",
    "]\n",
    "\n",
    "# Stack the results to get an array of shape (years, variables, lat, lon)\n",
    "days_reaching_50_result = da.stack(days_reaching_50_each_year)\n",
    "\n",
    "# Compute the result\n",
    "days_reaching_50_result_computed = days_reaching_50_result.compute()\n",
    "\n",
    "# Verification: Check some values from the result\n",
    "print(\n",
    "    \"Shape of days_reaching_50_result_computed:\", days_reaching_50_result_computed.shape\n",
    ")\n",
    "print(\"Days reaching 50 for tmean (variable 0) in year 1:\")\n",
    "print(days_reaching_50_result_computed[0, 0])\n",
    "print(\"\\nDays reaching 50 for tmax (variable 1) in year 1:\")\n",
    "print(days_reaching_50_result_computed[0, 1])\n",
    "print(\"\\nDays reaching 50 for tmean (variable 0) in year 2:\")\n",
    "print(days_reaching_50_result_computed[1, 0])\n",
    "print(\"\\nDays reaching 50 for tmax (variable 1) in year 2:\")\n",
    "print(days_reaching_50_result_computed[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_reaching_50_result.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
